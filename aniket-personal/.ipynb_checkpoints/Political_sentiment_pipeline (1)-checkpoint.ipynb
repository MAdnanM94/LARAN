{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0288f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: update in /home/aniket/anaconda3/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: sklearn in /home/aniket/.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: style==1.1.0 in /home/aniket/anaconda3/lib/python3.8/site-packages (from update) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /home/aniket/anaconda3/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/aniket/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/aniket/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/aniket/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/aniket/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/aniket/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aniket/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn==1.1\n",
    "!conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.metrics import roc_curve\n",
    "import math\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "path = '/Users/nikhil/data/ML_examples/erdos/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b8bce",
   "metadata": {},
   "source": [
    "Let us import the debate speech data and specify a list unwated words that must be romoved from the speech data. These words are moderator names and states names that are meaningless to our model. We will also define a list of election terms with their start and end dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c720b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_data = pd.read_csv('finaldata_party.csv')\n",
    "\n",
    "election_term = [1960,1976,1980,1984,1988,1992,1996,2000,2004,2012,2016]\n",
    "start_dates = ['1960-01-01','1976-01-01','1980-01-01','1984-01-01','1988-01-25','1992-01-01','1996-01-01','2000-01-01','2004-01-01','2012-01-01','2016-01-01']\n",
    "end_dates = ['1976-01-01','1980-01-01','1984-01-01','1988-01-01','1992-01-01','1996-01-01','2000-01-01','2004-01-01','2008-01-01','2016-01-01','2022-01-01']\n",
    "\n",
    "moderators = ['Dorothy Ridings', 'Sander Vanocur', 'John Mashek', 'Jack White',\n",
    "       'Norma Quarles', 'Robert Boyd', 'Jim Lehrer', 'Ann Compton',\n",
    "       'Moderator', 'Martha Raddatz', 'Bill Shadel', 'Frank McGee',\n",
    "       'Charles Van Fremd', 'Douglass Cater', 'Rosco Drummond',\n",
    "       'Bernard Shaw', 'Margaret Warner', 'Andrea Mitchell', 'Hal Bruno',\n",
    "       'Bob Schieffer', 'Unknown', 'Carol Simpson', 'Question',\n",
    "       'Kate Kelly', 'Gary Johnson', 'Bernie Sanders', 'Howard Smith',\n",
    "       'Walter Cronkite', 'Candy Crowley', 'Audience', 'Helen Thomas',\n",
    "       'Gene Gibbons', 'Chris Wallace', 'Quincy Howe', 'Frank Singiser',\n",
    "       'John Edwards', 'John Chancellor', 'Edwin Newman', 'Georgie Geyer',\n",
    "       'Marvin Kalb', 'Morton Kondracke', 'Barbara Walters',\n",
    "       'Joseph Kraft', 'Robert Maynard', 'Jack Nelson', 'Marvin Stone',\n",
    "       'Harry Ellis', 'William Hilliard', 'Elaine Quijano',\n",
    "       'Judy Woodruff', 'Jon Margolis', 'Tom Brokaw', 'Brit Hume',\n",
    "       'Gwen Ifill', 'Pauline Frederick', 'Max Frankel', 'Henry Trewitt',\n",
    "       'Richard Valeriani', 'Paul Niven', 'Edward Morgan', 'Alvin Spivak',\n",
    "       'Harold Levy', 'James Wieghart', 'Dianne Sawyer', 'Fred Barnes',\n",
    "       'Charles Gibson', 'Anderson Cooper', 'John Anderson',\n",
    "       'Bill Moyers', 'Carol Loomis', 'Daniel Greenberg',\n",
    "       'Charles Corddry', 'Lee May', 'Washington Post', 'Bryant Quinn',\n",
    "       'New York Times', 'Soma Golden', 'Frank Reynolds', 'James Gannon',\n",
    "       'Elizabeth Drew', 'Anne Groer', 'Peter Jennings', 'Bob Fleming',\n",
    "       'Stuart Novins', 'Charles Warren', 'Voiceover', 'Lester Holt',\n",
    "       'Franchesca Ramsey', 'Connor Franta', 'Marques Brownlee',\n",
    "       'Dana Bash', 'Don Lemon', 'Juan Carlos Lopez', 'David Muir',\n",
    "       'Neil Levesque', 'Josh McElveen', 'Rachel Maddow',\n",
    "       'Kristen Welker', 'Ashley Parker', 'Erin Burnett', 'Marc Lacey',\n",
    "       'Jake Tapper', 'Marrianne Williamson', 'John King',\n",
    "       'Nia-Malika Henderson', 'Michael Bennet', 'crowd',\n",
    "       'George Stephanopoulos', 'Jorge Ramos', 'Lindsey Davis',\n",
    "       'Wolf Blitzer', 'Abby Phillip', 'Brianne Pfannenstiel',\n",
    "       'Hallie Jackson', 'Chuck Todd', 'Vanessa Hauc', 'Jon Ralston',\n",
    "       'Protestors', 'Tim Alberta', 'Amna Nawaz', 'Yamiche Alcindor',\n",
    "       'Savannah Guthrie', 'Jose Diaz', 'Steve Kornacki', 'Lindsey David',\n",
    "       'Monica Hernandez', 'Adam Sexton', 'Linsey Davis', 'Devin Dwyer',\n",
    "       'Rachel Scott', 'Announcer', 'Steve King', \"Norah O'Donnell\",\n",
    "       'Candidate', 'Bill Whitaker', 'Major Garrett', 'Margaret Brennan',\n",
    "       'Ilia Caldern', 'Sanjay Gupta', 'Amy Langenfeld', 'David Gergen',\n",
    "       'Erick Erickson', 'Michelle Bachmann', 'Jim Demint',\n",
    "       'Unidentified', 'Resident', 'Bret Baier', 'Gerald Seib',\n",
    "       'Kelly Evans', 'Brian Williams', 'Shannon Bream', 'Rick Scott',\n",
    "       'Maria Bartiromo', 'John Harwood', 'Jim Cramer', 'Steve Liesman',\n",
    "       'Narrator', 'Doug Oberhelman', 'Rick Santelli', 'Sharon Epperson',\n",
    "       'Matt Strawn', 'Protester', 'Hugh Hewitt', 'Susan Page ']\n",
    "\n",
    "states = {\n",
    "    'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "states = list(states.values())\n",
    "moderator_names = []\n",
    "for w in moderators:\n",
    "    for a in w.split():\n",
    "        moderator_names.append(a.lower())\n",
    "\n",
    "states_names = []\n",
    "for w in states:\n",
    "    for a in w.split():\n",
    "        states_names.append(a.lower())\n",
    "\n",
    "unwanted_names = moderator_names + states_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cacda6",
   "metadata": {},
   "source": [
    "Now we will define few functions that will be used in our final Pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6733657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,min_date,max_date,type):\n",
    "        '''\n",
    "        Inputs:\n",
    "        min_date: Select the start date, format: \"YYYY-MM-DD\",(if None selects all dates)\n",
    "        max_date: Select the end date, format: \"YYYY-MM-DD\",(if None selects all dates)\n",
    "        type: List of debate types, e.g ['VP','Pres','Dem','Rep'],(if None all types will be considered)\n",
    "        \n",
    "        Output:\n",
    "        Debate Date, Debate Type selected data frame which contains only the 'Democratic' and 'Republican' party debates\n",
    "        with targets 0 for 'Republican' and 1 for 'Democratic'\n",
    "        '''\n",
    "        self.min_date = min_date\n",
    "        self.max_date = max_date\n",
    "        self.type = type\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.min_date!=None and self.max_date!=None:\n",
    "            X['date'] = pd.to_datetime(X['date'])\n",
    "            date_mask = (X['date'] > self.min_date) & (X['date'] <= self.max_date)\n",
    "            masked_data = X.loc[date_mask]\n",
    "        else:\n",
    "            masked_data = X\n",
    "    \n",
    "        if self.type!=None:\n",
    "            masked1_data = masked_data.loc[masked_data['type'].isin(self.type)]\n",
    "        else:\n",
    "            masked1_data = masked_data\n",
    "        masked2_data = masked1_data.loc[masked_data['party'].isin(['R','D'])]\n",
    "        masked2_data.loc[masked2_data['party'] == 'R', 'party'] = 0\n",
    "        masked2_data.loc[masked2_data['party'] == 'D', 'party'] = 1\n",
    "        masked2_data['party'] = masked2_data['party'].astype(int)\n",
    "        return masked2_data\n",
    "        \n",
    "def get_custom_stopwords(df_new,unwanted_names):\n",
    "    all_Text = df_new['text']\n",
    "    Tfidf = sk_text.TfidfVectorizer(lowercase=True,analyzer='word',stop_words='english',ngram_range=(1,1))\n",
    "    Tfidf.fit_transform(all_Text)\n",
    "    all_words = Tfidf.get_feature_names_out()\n",
    "    numeric_words = []\n",
    "    for w in all_words:\n",
    "        if not w.isalpha():\n",
    "           numeric_words.append(w)\n",
    "\n",
    "    candidates = df_new['speaker'].unique()\n",
    "    candidate_names = []\n",
    "    for w in candidates:\n",
    "        for a in w.split():\n",
    "            candidate_names.append(a.lower())\n",
    "        \n",
    "    stop_words = stopwords.words('english')\n",
    "    custom_stopwords = stop_words + numeric_words + candidate_names + unwanted_names\n",
    "    return custom_stopwords\n",
    "\n",
    "def lemmatizing_function(df, col_name, stopwords):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Input is the dataframe, the column name containing the text and the list of stopwords\n",
    "    lemmata = []\n",
    "    for obs in df[col_name]:\n",
    "        # Tokenizing the string in the observation\n",
    "        lemma = []\n",
    "        words = word_tokenize(obs)\n",
    "        # Iterating through the words\n",
    "        for word in words:\n",
    "            # Checking if not in stop words\n",
    "            if word.lower() not in stopwords:\n",
    "                w1 = lemmatizer.lemmatize(word.lower(), pos='n')\n",
    "                w2 = lemmatizer.lemmatize(w1, pos = 'v')\n",
    "                w3 = lemmatizer.lemmatize(w2, pos='a')\n",
    "                lemma.append(w3)\n",
    "                \n",
    "        # Combining into a sentence\n",
    "        new = ' '.join(lemma)\n",
    "        # Appending to the list of observations\n",
    "        lemmata.append(new)\n",
    "    # Appending to the dataframe\n",
    "    name = col_name + '_lemma'\n",
    "    df[name] = lemmata\n",
    "    return df\n",
    "\n",
    "def transform_custom_text(custom,custom_stopwords):\n",
    "    custom_test = pd.DataFrame(custom, columns=['text'])\n",
    "    custom_test_lemmatized = lemmatizing_function(custom_test,'text',custom_stopwords)\n",
    "    return custom_test_lemmatized\n",
    "\n",
    "def political_sentiment_analysis_pipeline(speech_data,election_term,start_dates,end_dates,custom_text,unwanted_names,classifier):\n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    accuracy = {}\n",
    "    f1score = {}\n",
    "    recall_train = {}\n",
    "    precision_train = {}\n",
    "    accuracy_train = {}\n",
    "    f1score_train = {}\n",
    "    custom_thresholds = {}\n",
    "    democratic_probability = np.zeros((len(election_term),len(custom_text)))\n",
    "    for i in range(0,len(start_dates)):\n",
    "        term = election_term[i]\n",
    "        start = start_dates[i]\n",
    "        end = end_dates[i]\n",
    "        Transformer = Custom_Transformer(min_date=start,max_date=end,type=['Pres','VP'])\n",
    "        df_new = Transformer.fit_transform(speech_data)\n",
    "        Tfidf = sk_text.TfidfVectorizer(max_features=int(len(df_new)*0.7 - 10),lowercase=True,stop_words='english',analyzer='word',ngram_range=(1,1))\n",
    "        custom_stopwords = get_custom_stopwords(df_new,unwanted_names)\n",
    "        lemmatized_df = lemmatizing_function(df_new,'text',custom_stopwords)\n",
    "        df_train,df_test = train_test_split(lemmatized_df.copy(),test_size=0.3, random_state=42,stratify=lemmatized_df['party'])\n",
    "        X = df_train['text_lemma']\n",
    "        y = df_train['party']\n",
    "        X_test = df_test['text_lemma']\n",
    "        y_test = df_test['party']\n",
    "        Tfidf.fit_transform(df_train['text_lemma'])\n",
    "        Party_classifier = Pipeline([(\"Tfidf vectorizer\",Tfidf),(\"classifier\",classifier)])\n",
    "        Party_classifier.fit(X,y)\n",
    "        y_predict = Party_classifier.predict(X_test)\n",
    "        y_predict_prob = Party_classifier.predict_proba(X_test)[:,1]\n",
    "        y_predict_train = Party_classifier.predict(X)\n",
    "        y_predict_train_prob = Party_classifier.predict_proba(X)[:,1]\n",
    "        test_metrics = [precision_score(y_test,y_predict), recall_score(y_test,y_predict), f1_score(y_test,y_predict), accuracy_score(y_test,y_predict)]\n",
    "        train_metrics = [precision_score(y,y_predict_train), recall_score(y,y_predict_train), f1_score(y,y_predict_train), accuracy_score(y,y_predict_train)]\n",
    "        recall[term] = recall_score(y_test,y_predict)\n",
    "        precision[term] = precision_score(y_test,y_predict)\n",
    "        f1score[term] = f1_score(y_test,y_predict)\n",
    "        accuracy[term] = accuracy_score(y_test,y_predict)\n",
    "        recall_train[term] = recall_score(y,y_predict_train)\n",
    "        precision_train[term] = precision_score(y,y_predict_train)\n",
    "        f1score_train[term] = f1_score(y,y_predict_train)\n",
    "        accuracy_train[term] = accuracy_score(y,y_predict_train)\n",
    "        custom_test_lemmatized = transform_custom_text(custom_text,custom_stopwords)\n",
    "        precision_t, recall_t, thresholds_t = precision_recall_curve(y_test, y_predict_prob)\n",
    "        fscore_t = (2 * precision_t * recall_t) / (precision_t + recall_t)\n",
    "        ix_fscore = np.argmax(fscore_t)\n",
    "        custom_thresholds[term] = thresholds_t[ix_fscore]\n",
    "        y_custom = Party_classifier.predict_proba(custom_test_lemmatized['text_lemma'])[:,1]\n",
    "        democratic_probability[i,:] = y_custom\n",
    "    return democratic_probability, recall, recall_train, precision, precision_train, f1score, f1score_train, accuracy, accuracy_train, custom_thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4df62",
   "metadata": {},
   "source": [
    "The code will take in a list of custom words or text and output the probability of that word/text belonging to the Democratic party $P(D)$ as a function of time (from 1960-2020). Note that the data is only used for Republican and Democraatic party so probability of word belonging to Republicaan party $P(R) = 1 - P(D)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3739aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d89a7ed1cd10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mMNB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdemocratic_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrc_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_thresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolitical_sentiment_analysis_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melection_term\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munwanted_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMNB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-18bd584dab47>\u001b[0m in \u001b[0;36mpolitical_sentiment_analysis_pipeline\u001b[0;34m(speech_data, election_term, start_dates, end_dates, custom_text, unwanted_names, classifier)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mTfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mcustom_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_custom_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munwanted_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mlemmatized_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatizing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlemmatized_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'party'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-18bd584dab47>\u001b[0m in \u001b[0;36mget_custom_stopwords\u001b[0;34m(df_new, unwanted_names)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mTfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mTfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_Text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mnumeric_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "custom_text = ['We believe in democracy','Radical and conservative'\n",
    "               ,'Time to withdraw from syria','Russia'\n",
    "               ,'Climate change is real','Illegal immigrants'\n",
    "               ,'Environmental awareness','Tax the rich'\n",
    "               ,'Recession could hit anytime']\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "RF = RandomForestClassifier()\n",
    "democratic_probability,rc,rc_tr,pr,pr_tr,f1,f1_tr,acc,acc_tr,custom_thresholds = political_sentiment_analysis_pipeline(speech_data,election_term,start_dates,end_dates,custom_text,unwanted_names,MNB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae77fa",
   "metadata": {},
   "source": [
    "Lets plot the probability of the first 6 text/words as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(150,80))\n",
    "\n",
    "ft = 100\n",
    "lw = 15\n",
    "ltw = 15\n",
    "ltwm= 30\n",
    "pad_space=60\n",
    "lz=100\n",
    "ms=20000\n",
    "\n",
    "ax1 = f.add_subplot(231)\n",
    "ax1.plot(election_term,democratic_probability[:,0],c='b',linewidth=lw,label='Dem')\n",
    "ax1.plot(election_term,1-democratic_probability[:,0],c='r',linewidth=lw,label='Rep')\n",
    "ax1.scatter(election_term,list(custom_thresholds.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax1.plot()\n",
    "ax1.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax1.set_xlabel('time (years)',fontsize=ft)\n",
    "ax1.set_title(custom_text[0],fontsize=ft)\n",
    "ax1.legend(fontsize=ft)\n",
    "ax1.minorticks_on()\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax1.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax2 = f.add_subplot(232)\n",
    "ax2.plot(election_term,democratic_probability[:,1],c='b',linewidth=lw)\n",
    "ax2.plot(election_term,1-democratic_probability[:,1],c='r',linewidth=lw)\n",
    "ax2.scatter(election_term,list(custom_thresholds.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax2.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax2.set_xlabel('time (years)',fontsize=ft)\n",
    "ax2.set_title(custom_text[1],fontsize=ft)\n",
    "ax2.minorticks_on()\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax2.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax3 = f.add_subplot(233)\n",
    "ax3.plot(election_term,democratic_probability[:,2],c='b',linewidth=lw)\n",
    "ax3.plot(election_term,1-democratic_probability[:,2],c='r',linewidth=lw)\n",
    "ax3.scatter(election_term,list(custom_thresholds.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax3.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax3.set_xlabel('time (years)',fontsize=ft)\n",
    "ax3.set_title(custom_text[2],fontsize=ft)\n",
    "ax3.minorticks_on()\n",
    "ax3.set_ylim([0,1])\n",
    "ax3.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax3.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax3.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax4 = f.add_subplot(234)\n",
    "ax4.plot(election_term,democratic_probability[:,3],c='b',linewidth=lw)\n",
    "ax4.plot(election_term,1-democratic_probability[:,3],c='r',linewidth=lw)\n",
    "ax4.scatter(election_term,list(custom_thresholds.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax4.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax4.set_xlabel('time (years)',fontsize=ft)\n",
    "ax4.set_title(custom_text[3],fontsize=ft)\n",
    "ax4.minorticks_on()\n",
    "ax4.set_ylim([0,1])\n",
    "ax4.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax4.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax4.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax5 = f.add_subplot(235)\n",
    "ax5.plot(election_term,democratic_probability[:,4],c='b',linewidth=lw)\n",
    "ax5.plot(election_term,1-democratic_probability[:,4],c='r',linewidth=lw)\n",
    "ax5.scatter(election_term,list(custom_thresholds.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax5.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax5.set_xlabel('time (years)',fontsize=ft)\n",
    "ax5.set_title(custom_text[4],fontsize=ft)\n",
    "ax5.minorticks_on()\n",
    "ax5.set_ylim([0,1])\n",
    "ax5.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax5.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax5.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax6 = f.add_subplot(236)\n",
    "ax6.plot(election_term,democratic_probability[:,5],c='b',linewidth=lw)\n",
    "ax6.plot(election_term,1-democratic_probability[:,5],c='r',linewidth=lw)\n",
    "ax6.scatter(election_term,list(custom_thresholds.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax6.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax6.set_xlabel('time (years)',fontsize=ft)\n",
    "ax6.set_title(custom_text[5],fontsize=ft)\n",
    "ax6.minorticks_on()\n",
    "ax6.set_ylim([0,1])\n",
    "ax6.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax6.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax6.spines[axis].set_linewidth(lw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33338ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(100,80))\n",
    "\n",
    "ft = 100\n",
    "lw = 10\n",
    "ltw = 15\n",
    "ltwm= 30\n",
    "pad_space=50\n",
    "lz=100\n",
    "\n",
    "ax1 = f.add_subplot(221)\n",
    "ax1.plot(election_term,list(rc.values()),c='g',linewidth=lw,label='Test')\n",
    "ax1.plot(election_term,list(rc_tr.values()),c='orange',linewidth=lw,label='Train')\n",
    "ax1.set_ylabel('Recall',fontsize=ft)\n",
    "ax1.set_xlabel('time (years)',fontsize=ft)\n",
    "ax1.legend(fontsize=ft)\n",
    "ax1.minorticks_on()\n",
    "ax1.set_ylim([0,1.2])\n",
    "ax1.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax1.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax2 = f.add_subplot(222)\n",
    "ax2.plot(election_term,list(pr.values()),c='g',linewidth=lw)\n",
    "ax2.plot(election_term,list(pr_tr.values()),c='orange',linewidth=lw)\n",
    "ax2.set_ylabel('Precision',fontsize=ft)\n",
    "ax2.set_xlabel('time (years)',fontsize=ft)\n",
    "ax2.minorticks_on()\n",
    "ax2.set_ylim([0,1.2])\n",
    "ax2.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax2.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax3 = f.add_subplot(223)\n",
    "ax3.plot(election_term,list(f1.values()),c='g',linewidth=lw)\n",
    "ax3.plot(election_term,list(f1_tr.values()),c='orange',linewidth=lw)\n",
    "ax3.set_ylabel('F1 score',fontsize=ft)\n",
    "ax3.set_xlabel('time (years)',fontsize=ft)\n",
    "ax3.minorticks_on()\n",
    "ax3.set_ylim([0,1.2])\n",
    "ax3.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax3.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax3.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax4 = f.add_subplot(224)\n",
    "ax4.plot(election_term,list(acc.values()),c='g',linewidth=lw)\n",
    "ax4.plot(election_term,list(acc_tr.values()),c='orange',linewidth=lw)\n",
    "ax4.set_ylabel('Accuracy',fontsize=ft)\n",
    "ax4.set_xlabel('time (years)',fontsize=ft)\n",
    "ax4.minorticks_on()\n",
    "ax4.set_ylim([0,1.2])\n",
    "ax4.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax4.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax4.spines[axis].set_linewidth(lw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96824c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "democratic_probability_rf,rc_rf,rc_tr_rf,pr_rf,pr_tr_rf,f1_rf,f1_tr_rf,acc_rf,acc_tr_rf,custom_thresholds_rf = political_sentiment_analysis_pipeline(speech_data,election_term,start_dates,end_dates,custom_text,unwanted_names,RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa83bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(150,80))\n",
    "\n",
    "ft = 100\n",
    "lw = 15\n",
    "ltw = 15\n",
    "ltwm= 30\n",
    "pad_space=60\n",
    "lz=100\n",
    "ms=20000\n",
    "\n",
    "ax1 = f.add_subplot(231)\n",
    "ax1.plot(election_term,democratic_probability_rf[:,0],c='b',linewidth=lw,label='Dem')\n",
    "ax1.plot(election_term,1-democratic_probability_rf[:,0],c='r',linewidth=lw,label='Rep')\n",
    "ax1.scatter(election_term,list(custom_thresholds_rf.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax1.plot()\n",
    "ax1.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax1.set_xlabel('time (years)',fontsize=ft)\n",
    "ax1.set_title(custom_text[0],fontsize=ft)\n",
    "ax1.legend(fontsize=ft)\n",
    "ax1.minorticks_on()\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax1.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax2 = f.add_subplot(232)\n",
    "ax2.plot(election_term,democratic_probability_rf[:,1],c='b',linewidth=lw)\n",
    "ax2.plot(election_term,1-democratic_probability_rf[:,1],c='r',linewidth=lw)\n",
    "ax2.scatter(election_term,list(custom_thresholds_rf.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax2.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax2.set_xlabel('time (years)',fontsize=ft)\n",
    "ax2.set_title(custom_text[1],fontsize=ft)\n",
    "ax2.minorticks_on()\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax2.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax3 = f.add_subplot(233)\n",
    "ax3.plot(election_term,democratic_probability_rf[:,2],c='b',linewidth=lw)\n",
    "ax3.plot(election_term,1-democratic_probability_rf[:,2],c='r',linewidth=lw)\n",
    "ax3.scatter(election_term,list(custom_thresholds_rf.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax3.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax3.set_xlabel('time (years)',fontsize=ft)\n",
    "ax3.set_title(custom_text[2],fontsize=ft)\n",
    "ax3.minorticks_on()\n",
    "ax3.set_ylim([0,1])\n",
    "ax3.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax3.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax3.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax4 = f.add_subplot(234)\n",
    "ax4.plot(election_term,democratic_probability_rf[:,3],c='b',linewidth=lw)\n",
    "ax4.plot(election_term,1-democratic_probability_rf[:,3],c='r',linewidth=lw)\n",
    "ax4.scatter(election_term,list(custom_thresholds_rf.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax4.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax4.set_xlabel('time (years)',fontsize=ft)\n",
    "ax4.set_title(custom_text[3],fontsize=ft)\n",
    "ax4.minorticks_on()\n",
    "ax4.set_ylim([0,1])\n",
    "ax4.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax4.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax4.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax5 = f.add_subplot(235)\n",
    "ax5.plot(election_term,democratic_probability_rf[:,4],c='b',linewidth=lw)\n",
    "ax5.plot(election_term,1-democratic_probability_rf[:,4],c='r',linewidth=lw)\n",
    "ax5.scatter(election_term,list(custom_thresholds_rf.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax5.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax5.set_xlabel('time (years)',fontsize=ft)\n",
    "ax5.set_title(custom_text[4],fontsize=ft)\n",
    "ax5.minorticks_on()\n",
    "ax5.set_ylim([0,1])\n",
    "ax5.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax5.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax5.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax6 = f.add_subplot(236)\n",
    "ax6.plot(election_term,democratic_probability_rf[:,5],c='b',linewidth=lw)\n",
    "ax6.plot(election_term,1-democratic_probability_rf[:,5],c='r',linewidth=lw)\n",
    "ax6.scatter(election_term,list(custom_thresholds_rf.values()),s=ms,c='k',marker='_',linewidth=lw-5)\n",
    "ax6.set_ylabel('P(D)/P(R)',fontsize=ft)\n",
    "ax6.set_xlabel('time (years)',fontsize=ft)\n",
    "ax6.set_title(custom_text[5],fontsize=ft)\n",
    "ax6.minorticks_on()\n",
    "ax6.set_ylim([0,1])\n",
    "ax6.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax6.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax6.spines[axis].set_linewidth(lw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(100,80))\n",
    "\n",
    "ft = 100\n",
    "lw = 10\n",
    "ltw = 15\n",
    "ltwm= 30\n",
    "pad_space=50\n",
    "lz=100\n",
    "\n",
    "ax1 = f.add_subplot(221)\n",
    "ax1.plot(election_term,list(rc_rf.values()),c='g',linewidth=lw,label='Test')\n",
    "ax1.plot(election_term,list(rc_tr_rf.values()),c='orange',linewidth=lw,label='Train')\n",
    "ax1.set_ylabel('Recall',fontsize=ft)\n",
    "ax1.set_xlabel('time (years)',fontsize=ft)\n",
    "ax1.legend(fontsize=ft)\n",
    "ax1.minorticks_on()\n",
    "ax1.set_ylim([0,1.2])\n",
    "ax1.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax1.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax2 = f.add_subplot(222)\n",
    "ax2.plot(election_term,list(pr_rf.values()),c='g',linewidth=lw)\n",
    "ax2.plot(election_term,list(pr_tr_rf.values()),c='orange',linewidth=lw)\n",
    "ax2.set_ylabel('Precision',fontsize=ft)\n",
    "ax2.set_xlabel('time (years)',fontsize=ft)\n",
    "ax2.minorticks_on()\n",
    "ax2.set_ylim([0,1.2])\n",
    "ax2.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax2.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax3 = f.add_subplot(223)\n",
    "ax3.plot(election_term,list(f1_rf.values()),c='g',linewidth=lw)\n",
    "ax3.plot(election_term,list(f1_tr_rf.values()),c='orange',linewidth=lw)\n",
    "ax3.set_ylabel('F1 score',fontsize=ft)\n",
    "ax3.set_xlabel('time (years)',fontsize=ft)\n",
    "ax3.minorticks_on()\n",
    "ax3.set_ylim([0,1.2])\n",
    "ax3.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax3.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax3.spines[axis].set_linewidth(lw)\n",
    "\n",
    "ax4 = f.add_subplot(224)\n",
    "ax4.plot(election_term,list(acc_rf.values()),c='g',linewidth=lw)\n",
    "ax4.plot(election_term,list(acc_tr_rf.values()),c='orange',linewidth=lw)\n",
    "ax4.set_ylabel('Accuracy',fontsize=ft)\n",
    "ax4.set_xlabel('time (years)',fontsize=ft)\n",
    "ax4.minorticks_on()\n",
    "ax4.set_ylim([0,1.2])\n",
    "ax4.tick_params(which='major',length=ltw,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "ax4.tick_params(which='minor',length=ltwm,width=lw,direction='in',labelsize=lz,axis='both',bottom=True,top=True,left=True,right=True,pad=pad_space)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "        ax4.spines[axis].set_linewidth(lw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35c2befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.1\n",
      "  Downloading scikit_learn-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/aniket/.local/lib/python3.8/site-packages (from scikit-learn==1.1) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/aniket/.local/lib/python3.8/site-packages (from scikit-learn==1.1) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/aniket/anaconda3/lib/python3.8/site-packages (from scikit-learn==1.1) (1.6.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/aniket/.local/lib/python3.8/site-packages (from scikit-learn==1.1) (1.0.1)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0\n",
      "    Uninstalling scikit-learn-1.0:\n",
      "      Successfully uninstalled scikit-learn-1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ktrain 0.31.2 requires scikit-learn==0.24.2, but you have scikit-learn 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.1.0\n",
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip3 install scikit-learn==1.1\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-walker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
